{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 赛事介绍\n",
    "实时对战游戏是人工智能研究领域的一个热点。由于游戏复杂性、部分可观察和动态实时变化战局等游戏特点使得研究变得比较困难。我们可以在选择英雄阶段预测胜负概率，也可以在比赛期间根据比赛实时数据进行建模。那么我们英雄联盟对局进行期间，能知道自己的胜率吗？\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/9739d3ca3cef4e32989a541af450a9556e91bf89a4e946e0a856cc2424321638)\n",
    "\n",
    "\n",
    "## 赛事任务\n",
    "比赛数据使用了英雄联盟玩家的实时游戏数据，记录下用户在游戏中对局数据（如击杀数、住物理伤害）。希望参赛选手能从数据集中挖掘出数据的规律，并预测玩家在本局游戏中的输赢情况。\n",
    "\n",
    "赛题训练集案例如下：\n",
    "- 训练集18万数据；\n",
    "- 测试集2万条数据；\n",
    "\n",
    "```plain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('train.csv.zip')\n",
    "```\n",
    "\n",
    "对于数据集中每一行为一个玩家的游戏数据，数据字段如下所示：\n",
    "\n",
    "* id：玩家记录id\n",
    "* win：是否胜利，标签变量\n",
    "* kills：击杀次数\n",
    "* deaths：死亡次数\n",
    "* assists：助攻次数\n",
    "* largestkillingspree：最大 killing spree（游戏术语，意味大杀特杀。当你连续杀死三个对方英雄而中途没有死亡时）\n",
    "* largestmultikill：最大mult ikill（游戏术语，短时间内多重击杀）\n",
    "* longesttimespentliving：最长存活时间\n",
    "* doublekills：doublekills次数\n",
    "* triplekills：doublekills次数\n",
    "* quadrakills：quadrakills次数\n",
    "* pentakills：pentakills次数\n",
    "* totdmgdealt：总伤害\n",
    "* magicdmgdealt：魔法伤害\n",
    "* physicaldmgdealt：物理伤害\n",
    "* truedmgdealt：真实伤害\n",
    "* largestcrit：最大暴击伤害\n",
    "* totdmgtochamp：对对方玩家的伤害\n",
    "* magicdmgtochamp：对对方玩家的魔法伤害\n",
    "* physdmgtochamp：对对方玩家的物理伤害\n",
    "* truedmgtochamp：对对方玩家的真实伤害\n",
    "* totheal：治疗量\n",
    "* totunitshealed：痊愈的总单位\n",
    "* dmgtoturrets：对炮塔的伤害\n",
    "* timecc：法控时间\n",
    "* totdmgtaken：承受的伤害\n",
    "* magicdmgtaken：承受的魔法伤害\n",
    "* physdmgtaken：承受的物理伤害\n",
    "* truedmgtaken：承受的真实伤害\n",
    "* wardsplaced：侦查守卫放置次数\n",
    "* wardskilled：侦查守卫摧毁次数\n",
    "* firstblood：是否为firstblood\n",
    "测试集中label字段win为空，需要选手预测。\n",
    "\n",
    "##  评审规则\n",
    "\n",
    "1. 数据说明\n",
    "\n",
    "选手需要提交测试集队伍排名预测，具体的提交格式如下：\n",
    "\n",
    "```plain\n",
    "win\n",
    "0\n",
    "1\n",
    "1\n",
    "0\n",
    "```\n",
    "\n",
    " 2. 评估指标\n",
    "\n",
    "本次竞赛的使用准确率进行评分，数值越高精度越高，评估代码参考：\n",
    "\n",
    "```\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [0, 2, 1, 3]\n",
    "y_true = [0, 1, 2, 3]\n",
    "accuracy_score(y_true, y_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import paddle\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "import seaborn as sns\n",
    "\n",
    "train_df = pd.read_csv('data/data137276/train.csv.zip')\n",
    "test_df = pd.read_csv('data/data137276/test.csv.zip')\n",
    "\n",
    "train_df = train_df.drop(['id', 'timecc'], axis=1)\n",
    "test_df = test_df.drop(['id', 'timecc'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2.Z-Score Normalization（Z分数归一化）\n",
    "for col in train_df.columns[1:]:\n",
    "    train_df[col] = (train_df[col]-train_df[col].mean()) / train_df[col].std()\n",
    "    test_df[col] = (test_df[col]-test_df[col].mean()) / test_df[col].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Classifier(paddle.nn.Layer):\n",
    "    # self代表类的实例自身\n",
    "    def __init__(self):\n",
    "        # 初始化父类中的一些参数\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.fc1 = paddle.nn.Linear(in_features=29, out_features=40)\n",
    "        self.fc2 = paddle.nn.Linear(in_features=40, out_features=1)\n",
    "        self.relu = paddle.nn.ReLU()\n",
    "    \n",
    "    # 网络的前向计算\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.fc1(inputs))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = paddle.optimizer.SGD(learning_rate=0.01, parameters=model.parameters())\n",
    "loss_fn = paddle.nn.BCEWithLogitsLoss()\n",
    "\n",
    "EPOCH_NUM = 1000   # 设置外层循环次数\n",
    "BATCH_SIZE = 100  # 设置batch大小\n",
    "training_data = train_df.iloc[:-1000,].values.astype(np.float32)\n",
    "val_data = train_df.iloc[-1000:, ].values.astype(np.float32)\n",
    "\n",
    "# 定义外层循环\n",
    "for epoch_id in range(EPOCH_NUM):\n",
    "    # 在每轮迭代开始之前，将训练数据的顺序随机的打乱\n",
    "    np.random.shuffle(training_data)\n",
    "\n",
    "    # 训练集测试，将训练数据进行拆分，每个batch包含10条数据\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    mini_batches = [training_data[k:k+BATCH_SIZE] for k in range(0, len(training_data), BATCH_SIZE)]\n",
    "    for iter_id, mini_batch in enumerate(mini_batches):\n",
    "        x = np.array(mini_batch[:, 1:]) # 获得当前批次训练数据\n",
    "        y = np.array(mini_batch[:, :1]) # 获得当前批次训练标签\n",
    "        \n",
    "        # 将numpy数据转为飞桨动态图tensor的格式\n",
    "        features = paddle.to_tensor(x)\n",
    "        y = paddle.to_tensor(y)\n",
    "        \n",
    "        # 前向计算\n",
    "        predicts = model(features)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = loss_fn(predicts, y, )\n",
    "        avg_loss = paddle.mean(loss)\n",
    "        train_loss.append(avg_loss.numpy())\n",
    "        \n",
    "        # 计算准确率\n",
    "        acc = (predicts > 0).astype(int).flatten() == y.flatten().astype(int)\n",
    "        acc = acc.astype(float).mean()\n",
    "        train_acc.append(acc.numpy())\n",
    "        \n",
    "        # 反向传播，计算每层参数的梯度值\n",
    "        avg_loss.backward()\n",
    "        # 更新参数，根据设置好的学习率迭代一步\n",
    "        opt.step()\n",
    "        # 清空梯度变量，以备下一轮计算\n",
    "        opt.clear_grad()\n",
    "\n",
    "    # 验证集测试\n",
    "    mini_batches = [val_data[k:k+BATCH_SIZE] for k in range(0, len(val_data), BATCH_SIZE)]\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    for iter_id, mini_batch in enumerate(mini_batches):\n",
    "        x = np.array(mini_batch[:, :-1])   # 获得当前批次训练数据\n",
    "        y = np.array(mini_batch[:, -1:])   # 获得当前批次训练标签\n",
    "        \n",
    "        # 将numpy数据转为飞桨动态图tensor的格式\n",
    "        features = paddle.to_tensor(x)\n",
    "        y = paddle.to_tensor(y)\n",
    "        \n",
    "        # 前向计算\n",
    "        predicts = model(features)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = loss_fn(predicts, y, )\n",
    "        avg_loss = paddle.mean(loss)\n",
    "        val_loss.append(avg_loss.numpy())\n",
    "\n",
    "        # 计算准确率\n",
    "        acc = (predicts > 0).astype(int).flatten() == y.flatten().astype(int)\n",
    "        acc = acc.astype(float).mean()\n",
    "        val_acc.append(acc.numpy())\n",
    "\n",
    "    print(f'Epoch {epoch_id}, train BCE {np.mean(train_loss)}, train Acc {np.mean(train_acc)},  val BCE {np.mean(val_loss)}, val Acc {np.mean(val_acc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_data = paddle.to_tensor(test_df.values.astype(np.float32))\n",
    "test_predict = model(test_data)\n",
    "test_predict = (test_predict > 0).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: submission.csv (deflated 90%)\r\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({'win':\n",
    "              test_predict.numpy()\n",
    "             }).to_csv('submission.csv', index=None)\n",
    "\n",
    "!zip submission.zip submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结与上分点\n",
    "\n",
    "1. 原始赛题字段存在关联，可以进一步提取交叉特征。\n",
    "2. 模型训练过程中可以加入验证集验证过程。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
